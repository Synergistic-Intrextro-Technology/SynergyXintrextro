# LLM Provider Configuration
# Set one or more of these to enable different providers

# OpenAI-compatible (default for most providers)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-3.5-turbo

# Azure OpenAI
AZURE_OPENAI_API_KEY=your_azure_openai_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Ollama (local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# HuggingFace Inference API
HUGGINGFACE_API_KEY=your_huggingface_token_here
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.1

# Evaluation Model (for LLM-as-judge benchmarks)
EVAL_MODEL=gpt-4
EVAL_PROVIDER=openai

# Application Configuration
SYNERGYX_LOG_LEVEL=INFO
SYNERGYX_DATA_DIR=./data
SYNERGYX_REPORTS_DIR=./reports

# API Configuration
SYNERGYX_API_HOST=0.0.0.0
SYNERGYX_API_PORT=8000

# Memory Configuration
SYNERGYX_MEMORY_MAX_MESSAGES=100
SYNERGYX_MEMORY_FILE=./data/conversations.jsonl

# RAG Configuration
SYNERGYX_RAG_DOCS_DIR=./docs
SYNERGYX_RAG_INDEX_PATH=./data/rag_index
SYNERGYX_RAG_CHUNK_SIZE=500
SYNERGYX_RAG_CHUNK_OVERLAP=50

# Benchmark Configuration
SYNERGYX_BENCH_DATASET_DIR=./data/benchmarks
SYNERGYX_BENCH_SMOKE_SAMPLES=3
SYNERGYX_BENCH_FULL_SAMPLES=50